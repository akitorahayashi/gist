# ----------------------------------------------------------------------
# Application Settings
# ----------------------------------------------------------------------

# The full URL to the Large Language Model (LLM) API endpoint.
# This is required for the summarization service to function.
# On Docker, use `host.docker.internal` to connect to a service running on your host machine.
# Example: http://host.docker.internal:8080
LLM_API_ENDPOINT=http://host.docker.internal:8080

# The specific model identifier to be used for summarization.
# Defaults to 'qwen3:0.6b' if not set.
# Example: qwen3:0.6b
SUMMARIZATION_MODEL=qwen3:0.6b

# The maximum number of characters for the generated summary.
# Defaults to 600 if not set.
SUMMARY_MAX_CHARS=600


# ----------------------------------------------------------------------
# Nginx Proxy Settings
# ----------------------------------------------------------------------

# The IP address on the host machine where the Nginx proxy will bind.
# Using 127.0.0.1 makes the application accessible only from the local machine.
# Using 0.0.0.0 would make it accessible from other devices on the same network.
# Defaults to 127.0.0.1.
HOST_BIND_IP=127.0.0.1

# The port on the host machine that Nginx will listen on.
# This is the port you will use to access the application in your browser.
# Defaults to 8000.
HOST_PORT=8000
